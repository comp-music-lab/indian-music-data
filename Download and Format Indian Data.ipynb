{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8ac92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import scipy.stats as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee87c6",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fe02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(group, region, demographic, iterand):\n",
    "    REGION_MAP = {\"north\": ['A', 'B'], \"south\": ['C', 'D']}\n",
    "    CATEGORY_MAP = {\"musician\": \"X\", \"non-musician\": \"Y\"}\n",
    "    filename = str(group)+REGION_MAP[region][iterand] + CATEGORY_MAP[demographic]+str(group)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b8cf9",
   "metadata": {},
   "source": [
    "# Pairwise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937a5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('./json/pairwise.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "data = json.load(f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "for item in data:\n",
    "    user = item['username']\n",
    "    similarity = item['similarity']\n",
    "    # open the file in the write mode\n",
    "    with open('./output/india/pairwise/raw/'+str(user)+'.csv', 'w', newline='\\n') as f:\n",
    "        rows = similarity.split('\\n')\n",
    "        for row in rows:\n",
    "            characters = row.split(',')\n",
    "            line = []\n",
    "            for x in characters:\n",
    "                try:\n",
    "                    line.append(int(x))\n",
    "                except:\n",
    "                    line.append('')\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32bd91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(demographic, group):\n",
    "    if demographic == 'north':\n",
    "        ids = ['AX', 'BX', 'AY', 'BY']\n",
    "    elif demographic == 'south':\n",
    "        ids = ['CX', 'DX', 'CY', 'DY']\n",
    "    elif demographic == 'musician':\n",
    "        ids = ['AX', 'BX', 'CX', 'DX']\n",
    "    elif demographic == 'non':\n",
    "        ids = ['AY', 'BY', 'CY', 'DY']\n",
    "    else:\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'AY', 'BY', 'CY', 'DY']\n",
    "    return [str(group)+element+str(group) for element in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97417a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(group_1, group_2):\n",
    "    interesect = [pid for pid in group_1 if pid in group_2]\n",
    "    return interesect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02623f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0AY0', '0BY0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = generate_id('north', 0)\n",
    "b = generate_id('non', 0)\n",
    "intersection(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4064d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pair_group_data(first_id, participants):\n",
    "    PATH = './output/india/pairwise/raw/'\n",
    "    sum_df = pd.read_csv(PATH+first_id+'.csv', header=None).fillna(0)\n",
    "    for pid in participants:\n",
    "        df2 = pd.read_csv(PATH+pid+'.csv', header=None).fillna(0)\n",
    "        sum_df = sum_df.add(df2, fill_value=0)\n",
    "    average = sum_df.div(len(participants)+1)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4c6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pair_data(category):\n",
    "    empty_df = pd.DataFrame(index=range(30),columns=range(30)).fillna(0)\n",
    "\n",
    "    group_0_ids = generate_id(category,0)\n",
    "    group_0 = average_pair_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "    empty_df.iloc[0:5,0:5] = group_0\n",
    "\n",
    "    group_1_ids = generate_id(category,1)\n",
    "    group_1 = average_pair_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "    empty_df.iloc[5:10,5:10] = group_1\n",
    "\n",
    "    group_2_ids = generate_id(category,2)\n",
    "    group_2 = average_pair_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "    empty_df.iloc[10:15,10:15] = group_2\n",
    "\n",
    "\n",
    "    group_3_ids = generate_id(category, 3)\n",
    "    group_3 = average_pair_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "    empty_df.iloc[15:20,15:20] = group_3\n",
    "\n",
    "    group_4_ids = generate_id(category, 4)\n",
    "    group_4 = average_pair_group_data(group_4_ids[0], group_4_ids[1:])\n",
    "    empty_df.iloc[20:25,20:25] = group_4\n",
    "\n",
    "    group_5_ids = generate_id(category, 5)\n",
    "    group_5 = average_pair_group_data(group_5_ids[0], group_5_ids[1:])\n",
    "    empty_df.iloc[25:30,25:30] = group_5\n",
    "\n",
    "    empty_df.to_csv('./output/india/pairwise/full_'+category+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d8f1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pair_data('all')\n",
    "save_pair_data('north')\n",
    "save_pair_data('south')\n",
    "save_pair_data('musician')\n",
    "save_pair_data('non')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9872ed",
   "metadata": {},
   "source": [
    "## Intra rater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61487707",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(PATH\u001b[38;5;241m+\u001b[39mgroup_0_ids[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# results.loc[len(results)] = list_row\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m r, p \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpearsonr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4104\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   4100\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(xm\u001b[38;5;241m/\u001b[39mnormxm, ym\u001b[38;5;241m/\u001b[39mnormym)\n\u001b[1;32m   4102\u001b[0m \u001b[38;5;66;03m# Presumably, if abs(r) > 1, then it is only some small artifact of\u001b[39;00m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;66;03m# floating point arithmetic.\u001b[39;00m\n\u001b[0;32m-> 4104\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m   4106\u001b[0m \u001b[38;5;66;03m# As explained in the docstring, the p-value can be computed as\u001b[39;00m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;66;03m#     p = 2*dist.cdf(-abs(r))\u001b[39;00m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;66;03m# where dist is the beta distribution on [-1, 1] with shape parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4112\u001b[0m \u001b[38;5;66;03m# becomes x = (-abs(r) + 1)/2 = 0.5*(1 - abs(r)).  (r is cast to float64\u001b[39;00m\n\u001b[1;32m   4113\u001b[0m \u001b[38;5;66;03m# to avoid a TypeError raised by btdtr when r is higher precision.)\u001b[39;00m\n\u001b[1;32m   4114\u001b[0m ab \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "PATH='./output/india/pairwise/raw/'\n",
    "\n",
    "group_0_ids = generate_id('all',0)\n",
    "results = pd.DataFrame(columns=['ID1', 'ID2', 'r', 'p-value'])\n",
    "\n",
    "# combinations(group_0_ids, 2)\n",
    "# subsets = list(itertools.)\n",
    "# subset = subsets[0]\n",
    "df1 = pd.read_csv(PATH+group_0_ids[0]+'.csv', header=None).fillna(0)\n",
    "df2 = pd.read_csv(PATH+group_0_ids[1]+'.csv', header=None).fillna(0)\n",
    "# results.loc[len(results)] = list_row\n",
    "r, p = sp.pearsonr(df1,df2)\n",
    "# for subset in itertools.combinations(group_0_ids, 2):\n",
    "#     df1 = pd.read_csv(PATH+subset[0]+'.csv', header=None).fillna(0)\n",
    "#     df2 = pd.read_csv(PATH+subset[1]+'.csv', header=None).fillna(0)\n",
    "#     results.loc[len(results)] = list_row\n",
    "#     r, p = sp.pearsonr(df1,df2)\n",
    "#     list_row = [subset[0], subset[1], ]\n",
    "# def calculate_correlation(participants):\n",
    "#     list(itertools.permutations([1, 2, 3]))\n",
    "#     for i in len(participants):\n",
    "#         for j in len(participants)-1:\n",
    "#             df2 = pd.read_csv(PATH+pid+'.csv', header=None).fillna(0)\n",
    "#             sum_df = sum_df.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3b8d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_distance_matrix(numpy_array):\n",
    "    arr = []\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if i<j:\n",
    "                arr.append(numpy_array[i,j])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f5434fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0AX0\n",
      "1AX1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     npar \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(PATH\u001b[38;5;241m+\u001b[39mpid\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pid)\n\u001b[0;32m----> 8\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mflatten_distance_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpar\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     indian_pairwise\u001b[38;5;241m.\u001b[39mextend(x)\n\u001b[1;32m     10\u001b[0m indian_pairwise \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m (x \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m indian_pairwise]\n",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36mflatten_distance_matrix\u001b[0;34m(numpy_array)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m<\u001b[39mj:\n\u001b[0;32m----> 6\u001b[0m             arr\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnumpy_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "PATH = './output/india/pairwise/raw/'\n",
    "\n",
    "indian_pairwise = []\n",
    "for i in range(6):\n",
    "    pid = str(i)+'AX'+str(i)\n",
    "    npar = pd.read_csv(PATH+pid+'.csv').to_numpy()\n",
    "    print(pid)\n",
    "    x = flatten_distance_matrix(npar[i*5:(i*5)+5, i*5:(i*5)+5])\n",
    "    indian_pairwise.extend(x)\n",
    "indian_pairwise = [1- (x / 100) for x in indian_pairwise]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8041c828",
   "metadata": {},
   "source": [
    "## Groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f03a65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pair_intersect_data(category1, category2):\n",
    "    empty_df = pd.DataFrame(index=range(30),columns=range(30)).fillna(0)\n",
    "\n",
    "    group_0_ids_a = generate_id(category1,0)\n",
    "    group_0_ids_b = generate_id(category2,0)\n",
    "    group_0_ids = intersection(group_0_ids_a, group_0_ids_b)\n",
    "    group_0 = average_pair_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "    empty_df.iloc[0:5,0:5] = group_0\n",
    "\n",
    "    group_1_ids_a = generate_id(category1,1)\n",
    "    group_1_ids_b = generate_id(category2,1)\n",
    "    group_1_ids = intersection(group_1_ids_a, group_1_ids_b)\n",
    "    group_1 = average_pair_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "    empty_df.iloc[5:10,5:10] = group_1\n",
    "\n",
    "    group_2_ids_a = generate_id(category1,2)\n",
    "    group_2_ids_b = generate_id(category2,2)\n",
    "    group_2_ids = intersection(group_2_ids_a, group_2_ids_b)\n",
    "    group_2 = average_pair_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "    empty_df.iloc[10:15,10:15] = group_2\n",
    "\n",
    "\n",
    "    group_3_ids_a = generate_id(category1,3)\n",
    "    group_3_ids_b = generate_id(category2,3)\n",
    "    group_3_ids = intersection(group_3_ids_a, group_3_ids_b)\n",
    "    group_3 = average_pair_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "    empty_df.iloc[15:20,15:20] = group_3\n",
    "\n",
    "    group_4_ids_a = generate_id(category1,4)\n",
    "    group_4_ids_b = generate_id(category2,4)\n",
    "    group_4_ids = intersection(group_4_ids_a, group_4_ids_b)\n",
    "    group_4 = average_pair_group_data(group_4_ids[0], group_4_ids[1:])\n",
    "    empty_df.iloc[20:25,20:25] = group_4\n",
    "\n",
    "    group_5_ids_a = generate_id(category1,5)\n",
    "    group_5_ids_b = generate_id(category2,5)\n",
    "    group_5_ids = intersection(group_5_ids_a, group_5_ids_b)\n",
    "    group_5 = average_pair_group_data(group_5_ids[0], group_5_ids[1:])\n",
    "    empty_df.iloc[25:30,25:30] = group_5\n",
    "\n",
    "    empty_df.to_csv('./output/india/pairwise/full_'+category1+'_'+category2+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "932259c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pair_intersect_data('north', 'musician')\n",
    "save_pair_intersect_data('south', 'musician')\n",
    "save_pair_intersect_data('north', 'non')\n",
    "save_pair_intersect_data('south', 'non')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7f322",
   "metadata": {},
   "source": [
    "# Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6986490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('./json/evaluation.json')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for participant in data:\n",
    "    username = participant['username']\n",
    "    features = participant['matrix']\n",
    "    df = pd.DataFrame(features)\n",
    "    df.to_csv('./output/india/feature/raw/'+username+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec77fbc",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7d10cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_data(code):\n",
    "    PATH = './output/india/feature/raw/'\n",
    "    df = pd.read_csv(PATH+code+'.csv')\n",
    "    return df\n",
    "\n",
    "def average_group_data(first_id, participants):\n",
    "    sum_df = get_feature_data(first_id).drop([\"song_id\", \"edited\"], axis=1)\n",
    "    for pid in participants:\n",
    "        df2 = get_feature_data(pid).drop([\"song_id\", \"edited\"], axis=1)\n",
    "        sum_df = sum_df.add(df2, fill_value=0)\n",
    "    average = sum_df.div(len(participants)+1)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00754870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(demographic, group):\n",
    "    if demographic == 'north':\n",
    "        ids = ['AX', 'BX', 'AY', 'BY']\n",
    "    elif demographic == 'south':\n",
    "        ids = ['CX', 'DX', 'CY', 'DY']\n",
    "    elif demographic == 'musician':\n",
    "        ids = ['AX', 'BX', 'CX', 'DX']\n",
    "    elif demographic == 'non':\n",
    "        ids = ['AY', 'BY', 'CY', 'DY']\n",
    "    else:\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'AY', 'BY', 'CY', 'DY']\n",
    "    return [str(group)+element+str(group) for element in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e2897",
   "metadata": {},
   "source": [
    "# All Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f22fc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_feature(category):\n",
    "    group_0_ids = generate_id(category, 0)\n",
    "    group_0 = average_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "\n",
    "    group_1_ids = generate_id(category, 1)\n",
    "    group_1 = average_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "\n",
    "    group_2_ids = generate_id(category, 2)\n",
    "    group_2 = average_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "\n",
    "    group_3_ids = generate_id(category, 3)\n",
    "    group_3 = average_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "\n",
    "    group_4_ids = generate_id(category, 4)\n",
    "    group_4 = average_group_data(group_4_ids[0], group_4_ids[1:])\n",
    "\n",
    "    group_5_ids = generate_id(category, 5)\n",
    "    group_5 = average_group_data(group_5_ids[0], group_5_ids[1:])\n",
    "\n",
    "    df = pd.concat([group_0, group_1, group_2, group_3, group_4, group_5]).reset_index(drop=True)\n",
    "    df = df.round(2)\n",
    "\n",
    "    df.to_csv('./output/india/feature/full_'+category+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8fe39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_combined_feature(category1, category2):\n",
    "    group_0_ids_a = generate_id(category1,0)\n",
    "    group_0_ids_b = generate_id(category2,0)\n",
    "    group_0_ids = intersection(group_0_ids_a, group_0_ids_b)\n",
    "    group_0 = average_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "\n",
    "    group_1_ids_a = generate_id(category1,1)\n",
    "    group_1_ids_b = generate_id(category2,1)\n",
    "    group_1_ids = intersection(group_1_ids_a, group_1_ids_b)\n",
    "    group_1 = average_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "\n",
    "    group_2_ids_a = generate_id(category1,2)\n",
    "    group_2_ids_b = generate_id(category2,2)\n",
    "    group_2_ids = intersection(group_2_ids_a, group_2_ids_b)\n",
    "    group_2 = average_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "\n",
    "    group_3_ids_a = generate_id(category1,3)\n",
    "    group_3_ids_b = generate_id(category2,3)\n",
    "    group_3_ids = intersection(group_3_ids_a, group_3_ids_b)\n",
    "    group_3 = average_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "\n",
    "    group_4_ids_a = generate_id(category1,4)\n",
    "    group_4_ids_b = generate_id(category2,4)\n",
    "    group_4_ids = intersection(group_4_ids_a, group_4_ids_b)\n",
    "    group_4 = average_group_data(group_4_ids[0], group_4_ids[1:])\n",
    "\n",
    "    group_5_ids_a = generate_id(category1,5)\n",
    "    group_5_ids_b = generate_id(category2,5)\n",
    "    group_5_ids = intersection(group_5_ids_a, group_5_ids_b)\n",
    "    group_5 = average_group_data(group_5_ids[0], group_5_ids[1:])\n",
    "\n",
    "    df = pd.concat([group_0, group_1, group_2, group_3, group_4, group_5]).reset_index(drop=True)\n",
    "    df = df.round(2)\n",
    "\n",
    "    df.to_csv('./output/india/feature/full_'+category1+'_'+category2+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e809dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_full_feature('all')\n",
    "generate_full_feature('north')\n",
    "generate_full_feature('south')\n",
    "generate_full_feature('musician')\n",
    "generate_full_feature('non')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57246519",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_full_combined_feature('north', 'musician')\n",
    "generate_full_combined_feature('south', 'musician')\n",
    "generate_full_combined_feature('north', 'non')\n",
    "generate_full_combined_feature('south', 'non')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9121775",
   "metadata": {},
   "source": [
    "## Individual Distance Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a1999bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_distance(input_data):\n",
    "    data = squareform(pdist(input_data, metric='euclidean'))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30014074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc7c6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Ornamentation', 'Grooviness', 'Familiarity', 'Liking', 'Consonance', 'Valence', 'Excitement', 'Vocal Range', 'Sound Quality', 'Tempo', 'Rhythmic Regularity', 'Vocal Tension', 'Vocal Texture']\n",
    "\n",
    "feature_mappings = {\n",
    "    'overlap':'vocal_texture',\n",
    "    'creativity':'familiarity',\n",
    "    'likeness':'liking',\n",
    "    'tempo':'tempo',\n",
    "    'consonance':'consonance',\n",
    "    'emotion':'valence',\n",
    "    'decoration':'ornamentation',\n",
    "    'range':'vocal_range',\n",
    "    'quality':'sound_quality',\n",
    "    'rhythm':'rhythmic_regularity',\n",
    "    'excitingness':'excitement',\n",
    "    'groove':'grooviness',\n",
    "    'timbre':'vocal_tension'\n",
    "}\n",
    "\n",
    "full_feature = pd.read_csv('./output/india/feature/full_all.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_full.csv')\n",
    "    \n",
    "north = pd.read_csv('./output/india/feature/full_north.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(north[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_north.csv')\n",
    "\n",
    "south = pd.read_csv('./output/india/feature/full_south.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(south[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_south.csv')\n",
    "\n",
    "musician = pd.read_csv('./output/india/feature/full_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(musician[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_musician.csv')\n",
    "\n",
    "non = pd.read_csv('./output/india/feature/full_non_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(non[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_non_musician.csv')\n",
    "    \n",
    "north_musician = pd.read_csv('./output/india/feature/full_north_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(north_musician[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_north_musician.csv')\n",
    "\n",
    "south_musician = pd.read_csv('./output/india/feature/full_south_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(south_musician[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_south_musician.csv')\n",
    "\n",
    "south_non = pd.read_csv('./output/india/feature/full_south_non.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(south_non[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_south_non.csv')\n",
    "\n",
    "north_non = pd.read_csv('./output/india/feature/full_north_non.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(north_non[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_north_non.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58891496",
   "metadata": {},
   "source": [
    "# Bollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed4d3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('./json/bollywood.json')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for participant in data:\n",
    "    username = participant['username']\n",
    "    features = participant['matrix']\n",
    "    df = pd.DataFrame(features)\n",
    "    df.to_csv('./output/india/bollywood/raw/'+username+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5f688205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bollywood_id(demographic, group):\n",
    "    if demographic == 'north':\n",
    "        ids = ['AX', 'BX', 'AY', 'BY', 'EX', 'EY', 'FX', 'FY']\n",
    "    elif demographic == 'south':\n",
    "        ids = ['CX', 'DX', 'CY', 'DY', 'GX', 'HX', 'GY', 'HY']\n",
    "    elif demographic == 'musician':\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'EX', 'FX', 'GX', 'HX']\n",
    "    elif demographic == 'non':\n",
    "        ids = ['AY', 'BY', 'CY', 'DY', 'EY', 'FY', 'GY', 'HY']\n",
    "    else:\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'EX', 'FX', 'GX', 'HX', 'AY', 'BY', 'CY', 'DY', 'EY', 'FY', 'GY', 'HY']\n",
    "    return [str(group)+element+str(group) for element in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1136d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bollywood_feature_data(code):\n",
    "    PATH = './output/india/bollywood/raw/'\n",
    "    df = pd.read_csv(PATH+code+'.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fbd08ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_bollywood_group_data(first_id, participants):\n",
    "    sum_df = get_bollywood_feature_data(first_id).drop([\"id\", \"edited\"], axis=1)\n",
    "    total = len(participants)+1\n",
    "    for pid in participants:\n",
    "        try:\n",
    "            df2 = get_bollywood_feature_data(pid).drop([\"id\", \"edited\"], axis=1)\n",
    "            sum_df = sum_df.add(df2, fill_value=0)\n",
    "        except:\n",
    "            total = total - 1\n",
    "    average = sum_df.div(total)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7fc6a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_bollywood_feature(category):\n",
    "    group_0_ids = generate_bollywood_id(category, 0)\n",
    "    group_0 = average_bollywood_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "\n",
    "    group_1_ids = generate_bollywood_id(category, 1)\n",
    "    group_1 = average_bollywood_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "\n",
    "    group_2_ids = generate_bollywood_id(category, 2)\n",
    "    group_2 = average_bollywood_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "\n",
    "    group_3_ids = generate_bollywood_id(category, 3)\n",
    "    group_3 = average_bollywood_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "\n",
    "    df = pd.concat([group_0, group_1, group_2, group_3]).reset_index(drop=True)\n",
    "    df = df.round(2)\n",
    "    df.to_csv('./output/india/bollywood/full_'+category+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5b5a57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_full_bollywood_feature('all')\n",
    "generate_full_bollywood_feature('north')\n",
    "generate_full_bollywood_feature('south')\n",
    "generate_full_bollywood_feature('musician')\n",
    "generate_full_bollywood_feature('non')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "88bc82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature = pd.read_csv('./output/india/bollywood/full_all.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_full.csv')\n",
    "    \n",
    "north = pd.read_csv('./output/india/feature/full_north.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_north.csv')\n",
    "\n",
    "south = pd.read_csv('./output/india/feature/full_south.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_south.csv')\n",
    "\n",
    "musician = pd.read_csv('./output/india/feature/full_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_musician.csv')\n",
    "\n",
    "non = pd.read_csv('./output/india/feature/full_non_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_non_musician.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature = pd.read_csv('./output/india/bollywood/full_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6a272",
   "metadata": {},
   "source": [
    "# Flattened Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c5a8f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_distance_matrix(numpy_array):\n",
    "    arr = []\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if i<j:\n",
    "                arr.append(numpy_array[i,j])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9c4ca019",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './output/japan/similarity/'\n",
    "\n",
    "full_partial = []\n",
    "for i in range(6):\n",
    "    npar = pd.read_csv(PATH+str(i)+'_average_distance.csv').to_numpy()\n",
    "    x = flatten_distance_matrix(npar)\n",
    "    full_partial.extend(x)\n",
    "full_partial = [x/100 for x in full_partial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1c79239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "PATH = './output/japan/feature/'\n",
    "feature_names = ['Ornamentation', 'Grooviness', 'Familiarity', 'Liking', 'Consonance', 'Valence', 'Excitement', 'Vocal Range', 'Sound Quality', 'Tempo', 'Rhythmic Regularity', 'Vocal Tension', 'Vocal Texture']\n",
    "output = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(feature_names)+1):\n",
    "    label = feature_names[i-1].lower().replace(' ', '_')\n",
    "    npar = pd.read_csv(PATH+label+'_average.csv').to_numpy()\n",
    "    flattened_feature = []\n",
    "    for j in range(6):\n",
    "        flattened = flatten_distance_matrix(npar[j*5:(j*5)+5, j*5:(j*5)+5])\n",
    "        flattened_feature.extend(flattened)\n",
    "    r, p = stats.pearsonr(flattened_feature, full_partial)\n",
    "    output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
    "output = output.round(2)\n",
    "output.to_csv('./output/analysis/japan_feature_pairwise.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "701b7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "PATH = './output/india/pairwise/'\n",
    "\n",
    "indian_partial = []\n",
    "for i in range(6):\n",
    "    npar = pd.read_csv(PATH+'full_all.csv').to_numpy()\n",
    "    x = flatten_distance_matrix(npar[i*5:(i*5)+5, i*5:(i*5)+5])\n",
    "    indian_partial.extend(x)\n",
    "\n",
    "indian_partial = [1- (x / 100) for x in indian_partial]\n",
    "\n",
    "output = pd.DataFrame()\n",
    "PATH = './output/india/feature-distance/'\n",
    "feature_names = ['Ornamentation', 'Grooviness', 'Familiarity', 'Liking', 'Consonance', 'Valence', 'Excitement', 'Vocal Range', 'Sound Quality', 'Tempo', 'Rhythmic Regularity', 'Vocal Tension', 'Vocal Texture']\n",
    "labels = [x.lower().replace(' ', '_') for x in feature_names]\n",
    "for i in range(0, len(labels)):\n",
    "    label = labels[i]\n",
    "    npar = pd.read_csv(PATH+label+'_full.csv').to_numpy()\n",
    "    flattened_feature = []\n",
    "    for j in range(6):\n",
    "        flattened = flatten_distance_matrix(npar[j*5:(j*5)+5, j*5:(j*5)+5])\n",
    "        flattened_feature.extend(flattened)\n",
    "    r, p = stats.pearsonr(flattened_feature, indian_partial)\n",
    "    output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
    "output = output.round(2)\n",
    "output.to_csv('./output/analysis/india_feature_pairwise.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "039ead57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_japanese_feature_data(code):\n",
    "    PATH = './data/japanese/evaluation/evaluation_'\n",
    "    df = pd.read_csv(PATH+code+'.csv', header=None).drop([0,14], axis=1)\n",
    "    return df\n",
    "\n",
    "columns = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "participants = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "\n",
    "full_japan = pd.DataFrame(columns = columns)\n",
    "for i in range(6):\n",
    "    sum_df = pd.DataFrame(columns = columns)\n",
    "    for pid in participants:\n",
    "        df = get_japanese_feature_data(str(i)+pid)\n",
    "        sum_df = sum_df.add(df, fill_value=0)\n",
    "    average = sum_df.div(len(participants))\n",
    "    full_japan = pd.concat([full_japan,average]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72fdbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_japan.to_csv('./output/japan/feature/full_feature.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
