{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8ac92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import scipy.stats as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee87c6",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fe02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(group, region, demographic, iterand):\n",
    "    REGION_MAP = {\"north\": ['A', 'B'], \"south\": ['C', 'D']}\n",
    "    CATEGORY_MAP = {\"musician\": \"X\", \"non-musician\": \"Y\"}\n",
    "    filename = str(group)+REGION_MAP[region][iterand] + CATEGORY_MAP[demographic]+str(group)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b8cf9",
   "metadata": {},
   "source": [
    "# Pairwise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "937a5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('./json/pairwise.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "data = json.load(f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "for item in data:\n",
    "    user = item['username']\n",
    "    similarity = item['similarity']\n",
    "    # open the file in the write mode\n",
    "    with open('./output/india/pairwise/raw/'+str(user)+'.csv', 'w', newline='\\n') as f:\n",
    "        rows = similarity.split('\\n')\n",
    "        for row in rows:\n",
    "            characters = row.split(',')\n",
    "            line = []\n",
    "            for x in characters:\n",
    "                try:\n",
    "                    line.append(int(x))\n",
    "                except:\n",
    "                    line.append('')\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "32bd91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(demographic, group):\n",
    "    if demographic == 'north':\n",
    "        ids = ['AX', 'BX', 'AY', 'BY']\n",
    "    elif demographic == 'south':\n",
    "        ids = ['CX', 'DX', 'CY', 'DY']\n",
    "    elif demographic == 'musician':\n",
    "        ids = ['AX', 'BX', 'CX', 'DX']\n",
    "    elif demographic == 'non':\n",
    "        ids = ['AY', 'BY', 'CY', 'DY']\n",
    "    else:\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'AY', 'BY', 'CY', 'DY']\n",
    "    return [str(group)+element+str(group) for element in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4064d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pair_group_data(first_id, participants):\n",
    "    PATH = './output/india/pairwise/raw/'\n",
    "    sum_df = pd.read_csv(PATH+first_id+'.csv', header=None).fillna(0)\n",
    "    for pid in participants:\n",
    "        df2 = pd.read_csv(PATH+pid+'.csv', header=None).fillna(0)\n",
    "        sum_df = sum_df.add(df2, fill_value=0)\n",
    "    average = sum_df.div(len(participants)+1)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3a4c6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pair_data(category):\n",
    "    empty_df = pd.DataFrame(index=range(30),columns=range(30)).fillna(0)\n",
    "\n",
    "    group_0_ids = generate_id(category,0)\n",
    "    group_0 = average_pair_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "    empty_df.iloc[0:5,0:5] = group_0\n",
    "\n",
    "    group_1_ids = generate_id(category,1)\n",
    "    group_1 = average_pair_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "    empty_df.iloc[5:10,5:10] = group_1\n",
    "\n",
    "    group_2_ids = generate_id(category,2)\n",
    "    group_2 = average_pair_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "    empty_df.iloc[10:15,10:15] = group_2\n",
    "\n",
    "\n",
    "    group_3_ids = generate_id(category, 3)\n",
    "    group_3 = average_pair_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "    empty_df.iloc[15:20,15:20] = group_3\n",
    "\n",
    "    group_4_ids = generate_id(category, 4)\n",
    "    group_4 = average_pair_group_data(group_4_ids[0], group_4_ids[1:])\n",
    "    empty_df.iloc[20:25,20:25] = group_4\n",
    "\n",
    "    group_5_ids = generate_id(category, 5)\n",
    "    group_5 = average_pair_group_data(group_5_ids[0], group_5_ids[1:])\n",
    "    empty_df.iloc[25:30,25:30] = group_5\n",
    "\n",
    "    empty_df.to_csv('./output/india/pairwise/full_'+category+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9d8f1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pair_data('all')\n",
    "save_pair_data('north')\n",
    "save_pair_data('south')\n",
    "save_pair_data('musician')\n",
    "save_pair_data('non')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7f322",
   "metadata": {},
   "source": [
    "# Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6986490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('./json/evaluation.json')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for participant in data:\n",
    "    username = participant['username']\n",
    "    features = participant['matrix']\n",
    "    df = pd.DataFrame(features)\n",
    "    df.to_csv('./output/india/feature/raw/'+username+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435931f7",
   "metadata": {},
   "source": [
    "# Bollywood Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed4d3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('./json/bollywood.json')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for participant in data:\n",
    "    username = participant['username']\n",
    "    features = participant['matrix']\n",
    "    df = pd.DataFrame(features)\n",
    "    df.to_csv('./output/india/bollywood/raw/'+username+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec77fbc",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7d10cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_data(code):\n",
    "    PATH = './output/india/feature/raw/'\n",
    "    df = pd.read_csv(PATH+code+'.csv')\n",
    "    return df\n",
    "\n",
    "def average_group_data(first_id, participants):\n",
    "    sum_df = get_feature_data(first_id).drop([\"song_id\", \"edited\"], axis=1)\n",
    "    for pid in participants:\n",
    "        df2 = get_feature_data(pid).drop([\"song_id\", \"edited\"], axis=1)\n",
    "        sum_df = sum_df.add(df2, fill_value=0)\n",
    "    average = sum_df.div(len(participants)+1)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00754870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(demographic, group):\n",
    "    if demographic == 'north':\n",
    "        ids = ['AX', 'BX', 'AY', 'BY']\n",
    "    elif demographic == 'south':\n",
    "        ids = ['CX', 'DX', 'CY', 'DY']\n",
    "    elif demographic == 'musician':\n",
    "        ids = ['AX', 'BX', 'CX', 'DX']\n",
    "    elif demographic == 'non':\n",
    "        ids = ['AY', 'BY', 'CY', 'DY']\n",
    "    else:\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'AY', 'BY', 'CY', 'DY']\n",
    "    return [str(group)+element+str(group) for element in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e2897",
   "metadata": {},
   "source": [
    "# All Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f22fc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_feature(category):\n",
    "    group_0_ids = generate_id(category, 0)\n",
    "    group_0 = average_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "\n",
    "    group_1_ids = generate_id(category, 1)\n",
    "    group_1 = average_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "\n",
    "    group_2_ids = generate_id(category, 2)\n",
    "    group_2 = average_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "\n",
    "    group_3_ids = generate_id(category, 3)\n",
    "    group_3 = average_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "\n",
    "    group_4_ids = generate_id(category, 4)\n",
    "    group_4 = average_group_data(group_4_ids[0], group_4_ids[1:])\n",
    "\n",
    "    group_5_ids = generate_id(category, 5)\n",
    "    group_5 = average_group_data(group_5_ids[0], group_5_ids[1:])\n",
    "\n",
    "    df = pd.concat([group_0, group_1, group_2, group_3, group_4, group_5]).reset_index(drop=True)\n",
    "    df = df.round(2)\n",
    "\n",
    "    df.to_csv('./output/india/feature/full_'+category+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6e809dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_full_feature('all')\n",
    "generate_full_feature('north')\n",
    "generate_full_feature('south')\n",
    "generate_full_feature('musician')\n",
    "generate_full_feature('non')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9121775",
   "metadata": {},
   "source": [
    "## Individual Distance Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a1999bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_distance(input_data):\n",
    "    data = squareform(pdist(input_data, metric='euclidean'))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fc7c6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Ornamentation', 'Grooviness', 'Familiarity', 'Liking', 'Consonance', 'Valence', 'Excitement', 'Vocal Range', 'Sound Quality', 'Tempo', 'Rhythmic Regularity', 'Vocal Tension', 'Vocal Texture']\n",
    "\n",
    "feature_mappings = {\n",
    "    'overlap':'vocal_texture',\n",
    "    'creativity':'familiarity',\n",
    "    'likeness':'liking',\n",
    "    'tempo':'tempo',\n",
    "    'consonance':'consonance',\n",
    "    'emotion':'valence',\n",
    "    'decoration':'ornamentation',\n",
    "    'range':'vocal_range',\n",
    "    'quality':'sound_quality',\n",
    "    'rhythm':'rhythmic_regularity',\n",
    "    'excitingness':'excitement',\n",
    "    'groove':'grooviness',\n",
    "    'timbre':'vocal_tension'\n",
    "}\n",
    "\n",
    "full_feature = pd.read_csv('./output/india/feature/full_all.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_full.csv')\n",
    "    \n",
    "north = pd.read_csv('./output/india/feature/full_north.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_north.csv')\n",
    "\n",
    "south = pd.read_csv('./output/india/feature/full_south.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_south.csv')\n",
    "\n",
    "musician = pd.read_csv('./output/india/feature/full_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_musician.csv')\n",
    "\n",
    "non = pd.read_csv('./output/india/feature/full_non_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/feature-distance/'+feature_mappings[feature]+'_non_musician.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58891496",
   "metadata": {},
   "source": [
    "# Bollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5f688205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bollywood_id(demographic, group):\n",
    "    if demographic == 'north':\n",
    "        ids = ['AX', 'BX', 'AY', 'BY', 'EX', 'EY', 'FX', 'FY']\n",
    "    elif demographic == 'south':\n",
    "        ids = ['CX', 'DX', 'CY', 'DY', 'GX', 'HX', 'GY', 'HY']\n",
    "    elif demographic == 'musician':\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'EX', 'FX', 'GX', 'HX']\n",
    "    elif demographic == 'non':\n",
    "        ids = ['AY', 'BY', 'CY', 'DY', 'EY', 'FY', 'GY', 'HY']\n",
    "    else:\n",
    "        ids = ['AX', 'BX', 'CX', 'DX', 'EX', 'FX', 'GX', 'HX', 'AY', 'BY', 'CY', 'DY', 'EY', 'FY', 'GY', 'HY']\n",
    "    return [str(group)+element+str(group) for element in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1136d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bollywood_feature_data(code):\n",
    "    PATH = './output/india/bollywood/raw/'\n",
    "    df = pd.read_csv(PATH+code+'.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fbd08ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_bollywood_group_data(first_id, participants):\n",
    "    sum_df = get_bollywood_feature_data(first_id).drop([\"id\", \"edited\"], axis=1)\n",
    "    total = len(participants)+1\n",
    "    for pid in participants:\n",
    "        try:\n",
    "            df2 = get_bollywood_feature_data(pid).drop([\"id\", \"edited\"], axis=1)\n",
    "            sum_df = sum_df.add(df2, fill_value=0)\n",
    "        except:\n",
    "            total = total - 1\n",
    "    average = sum_df.div(total)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7fc6a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_bollywood_feature(category):\n",
    "    group_0_ids = generate_bollywood_id(category, 0)\n",
    "    group_0 = average_bollywood_group_data(group_0_ids[0], group_0_ids[1:])\n",
    "\n",
    "    group_1_ids = generate_bollywood_id(category, 1)\n",
    "    group_1 = average_bollywood_group_data(group_1_ids[0], group_1_ids[1:])\n",
    "\n",
    "    group_2_ids = generate_bollywood_id(category, 2)\n",
    "    group_2 = average_bollywood_group_data(group_2_ids[0], group_2_ids[1:])\n",
    "\n",
    "    group_3_ids = generate_bollywood_id(category, 3)\n",
    "    group_3 = average_bollywood_group_data(group_3_ids[0], group_3_ids[1:])\n",
    "\n",
    "    df = pd.concat([group_0, group_1, group_2, group_3]).reset_index(drop=True)\n",
    "    df = df.round(2)\n",
    "    df.to_csv('./output/india/bollywood/full_'+category+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5b5a57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_full_bollywood_feature('all')\n",
    "generate_full_bollywood_feature('north')\n",
    "generate_full_bollywood_feature('south')\n",
    "generate_full_bollywood_feature('musician')\n",
    "generate_full_bollywood_feature('non')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "88bc82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature = pd.read_csv('./output/india/bollywood/full_all.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_full.csv')\n",
    "    \n",
    "north = pd.read_csv('./output/india/feature/full_north.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_north.csv')\n",
    "\n",
    "south = pd.read_csv('./output/india/feature/full_south.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_south.csv')\n",
    "\n",
    "musician = pd.read_csv('./output/india/feature/full_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_musician.csv')\n",
    "\n",
    "non = pd.read_csv('./output/india/feature/full_non_musician.csv')\n",
    "for feature in full_feature.columns:\n",
    "    feature_df = pd.DataFrame(get_feature_distance(full_feature[[feature]]))\n",
    "    feature_df.to_csv('./output/india/bollywood-feature-distance/'+feature+'_non_musician.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature = pd.read_csv('./output/india/bollywood/full_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6a272",
   "metadata": {},
   "source": [
    "# Flattened Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c5a8f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_distance_matrix(numpy_array):\n",
    "    arr = []\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if i<j:\n",
    "                arr.append(numpy_array[i,j])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9c4ca019",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './output/japan/similarity/'\n",
    "\n",
    "full_partial = []\n",
    "for i in range(6):\n",
    "    npar = pd.read_csv(PATH+str(i)+'_average_distance.csv').to_numpy()\n",
    "    x = flatten_distance_matrix(npar)\n",
    "    full_partial.extend(x)\n",
    "full_partial = [x/100 for x in full_partial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1c79239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2467910764.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "PATH = './output/japan/feature/'\n",
    "feature_names = ['Ornamentation', 'Grooviness', 'Familiarity', 'Liking', 'Consonance', 'Valence', 'Excitement', 'Vocal Range', 'Sound Quality', 'Tempo', 'Rhythmic Regularity', 'Vocal Tension', 'Vocal Texture']\n",
    "output = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(feature_names)+1):\n",
    "    label = feature_names[i-1].lower().replace(' ', '_')\n",
    "    npar = pd.read_csv(PATH+label+'_average.csv').to_numpy()\n",
    "    flattened_feature = []\n",
    "    for j in range(6):\n",
    "        flattened = flatten_distance_matrix(npar[j*5:(j*5)+5, j*5:(j*5)+5])\n",
    "        flattened_feature.extend(flattened)\n",
    "    r, p = stats.pearsonr(flattened_feature, full_partial)\n",
    "    output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
    "output = output.round(2)\n",
    "output.to_csv('./output/analysis/japan_feature_pairwise.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "701b7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
      "/var/folders/t5/g46h2p3n4bx62qf44whk03240000gp/T/ipykernel_97152/2178472131.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "PATH = './output/india/pairwise/'\n",
    "\n",
    "indian_partial = []\n",
    "for i in range(6):\n",
    "    npar = pd.read_csv(PATH+'full_all.csv').to_numpy()\n",
    "    x = flatten_distance_matrix(npar[i*5:(i*5)+5, i*5:(i*5)+5])\n",
    "    indian_partial.extend(x)\n",
    "\n",
    "indian_partial = [1- (x / 100) for x in indian_partial]\n",
    "\n",
    "output = pd.DataFrame()\n",
    "PATH = './output/india/feature-distance/'\n",
    "feature_names = ['Ornamentation', 'Grooviness', 'Familiarity', 'Liking', 'Consonance', 'Valence', 'Excitement', 'Vocal Range', 'Sound Quality', 'Tempo', 'Rhythmic Regularity', 'Vocal Tension', 'Vocal Texture']\n",
    "labels = [x.lower().replace(' ', '_') for x in feature_names]\n",
    "for i in range(0, len(labels)):\n",
    "    label = labels[i]\n",
    "    npar = pd.read_csv(PATH+label+'_full.csv').to_numpy()\n",
    "    flattened_feature = []\n",
    "    for j in range(6):\n",
    "        flattened = flatten_distance_matrix(npar[j*5:(j*5)+5, j*5:(j*5)+5])\n",
    "        flattened_feature.extend(flattened)\n",
    "    r, p = stats.pearsonr(flattened_feature, indian_partial)\n",
    "    output = output.append({'Feature':feature_names[i-1], 'r':r, 'p-value':p}, ignore_index=True)\n",
    "output = output.round(2)\n",
    "output.to_csv('./output/analysis/india_feature_pairwise.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "039ead57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_japanese_feature_data(code):\n",
    "    PATH = './data/japanese/evaluation/evaluation_'\n",
    "    df = pd.read_csv(PATH+code+'.csv', header=None).drop([0,14], axis=1)\n",
    "    return df\n",
    "\n",
    "columns = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "participants = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "\n",
    "full_japan = pd.DataFrame(columns = columns)\n",
    "for i in range(6):\n",
    "    sum_df = pd.DataFrame(columns = columns)\n",
    "    for pid in participants:\n",
    "        df = get_japanese_feature_data(str(i)+pid)\n",
    "        sum_df = sum_df.add(df, fill_value=0)\n",
    "    average = sum_df.div(len(participants))\n",
    "    full_japan = pd.concat([full_japan,average]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72fdbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_japan.to_csv('./output/japan/feature/full_feature.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
